{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GzQYUXlHyUJ0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "uBJiZJHay7Ko"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextPreprocessor:\n",
        "    \"\"\"Advanced text preprocessing for text-to-image generation\"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size=1000, max_length=20):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_length = max_length\n",
        "        self.word_to_idx = {}\n",
        "        self.idx_to_word = {}\n",
        "        self.vocab_built = False\n",
        "\n",
        "        # Special tokens\n",
        "        self.PAD_TOKEN = '<PAD>'\n",
        "        self.UNK_TOKEN = '<UNK>'\n",
        "        self.START_TOKEN = '<START>'\n",
        "        self.END_TOKEN = '<END>'\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        \"\"\"Clean and normalize text\"\"\"\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove special characters except spaces and common punctuation\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s\\-_]', '', text)\n",
        "\n",
        "        # Remove extra whitespaces\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        return text\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Tokenize text into words\"\"\"\n",
        "        cleaned_text = self.clean_text(text)\n",
        "        tokens = cleaned_text.split()\n",
        "        return tokens\n",
        "\n",
        "    def build_vocabulary(self, texts):\n",
        "        \"\"\"Build vocabulary from list of texts\"\"\"\n",
        "        # Collect all words\n",
        "        all_words = []\n",
        "        for text in texts:\n",
        "            tokens = self.tokenize(text)\n",
        "            all_words.extend(tokens)\n",
        "\n",
        "        # Count word frequencies\n",
        "        word_counts = Counter(all_words)\n",
        "\n",
        "        # Select most frequent words\n",
        "        most_common = word_counts.most_common(self.vocab_size - 4)  # Reserve 4 for special tokens\n",
        "\n",
        "        # Build vocabulary\n",
        "        self.word_to_idx = {\n",
        "            self.PAD_TOKEN: 0,\n",
        "            self.UNK_TOKEN: 1,\n",
        "            self.START_TOKEN: 2,\n",
        "            self.END_TOKEN: 3\n",
        "        }\n",
        "\n",
        "        for i, (word, _) in enumerate(most_common):\n",
        "            self.word_to_idx[word] = i + 4\n",
        "\n",
        "        # Build reverse mapping\n",
        "        self.idx_to_word = {idx: word for word, idx in self.word_to_idx.items()}\n",
        "        self.vocab_built = True\n",
        "\n",
        "        print(f\"Built vocabulary with {len(self.word_to_idx)} words\")\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        \"\"\"Encode text to sequence of indices\"\"\"\n",
        "        if not self.vocab_built:\n",
        "            raise ValueError(\"Vocabulary not built. Call build_vocabulary first.\")\n",
        "\n",
        "        tokens = self.tokenize(text)\n",
        "\n",
        "        # Add special tokens\n",
        "        tokens = [self.START_TOKEN] + tokens + [self.END_TOKEN]\n",
        "\n",
        "        # Convert to indices\n",
        "        indices = []\n",
        "        for token in tokens:\n",
        "            if token in self.word_to_idx:\n",
        "                indices.append(self.word_to_idx[token])\n",
        "            else:\n",
        "                indices.append(self.word_to_idx[self.UNK_TOKEN])\n",
        "\n",
        "        # Pad or truncate to max_length\n",
        "        if len(indices) < self.max_length:\n",
        "            indices.extend([self.word_to_idx[self.PAD_TOKEN]] * (self.max_length - len(indices)))\n",
        "        else:\n",
        "            indices = indices[:self.max_length]\n",
        "\n",
        "        return torch.tensor(indices, dtype=torch.long)\n",
        "\n",
        "    def decode_text(self, indices):\n",
        "        \"\"\"Decode sequence of indices back to text\"\"\"\n",
        "        if isinstance(indices, torch.Tensor):\n",
        "            indices = indices.cpu().numpy()\n",
        "\n",
        "        words = []\n",
        "        for idx in indices:\n",
        "            if idx in self.idx_to_word:\n",
        "                word = self.idx_to_word[idx]\n",
        "                if word not in [self.PAD_TOKEN, self.START_TOKEN, self.END_TOKEN]:\n",
        "                    words.append(word)\n",
        "\n",
        "        return ' '.join(words)"
      ],
      "metadata": {
        "id": "Uh6KQbyjy7HQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\n",
        "        super(TextEmbedding, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Word embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # LSTM for sequence processing\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.MultiheadAttention(hidden_dim * 2, num_heads=8, batch_first=True)\n",
        "\n",
        "        # Final projection\n",
        "        self.projection = nn.Linear(hidden_dim * 2, embedding_dim)\n",
        "\n",
        "    def forward(self, text_indices):\n",
        "        # Embed tokens\n",
        "        embedded = self.embedding(text_indices)  # (batch, seq_len, embed_dim)\n",
        "\n",
        "        # LSTM processing\n",
        "        lstm_out, _ = self.lstm(embedded)  # (batch, seq_len, hidden_dim * 2)\n",
        "\n",
        "        # Self-attention\n",
        "        attended, _ = self.attention(lstm_out, lstm_out, lstm_out)\n",
        "\n",
        "        # Global average pooling (ignoring padding)\n",
        "        mask = (text_indices != 0).float().unsqueeze(-1)  # Padding mask\n",
        "        attended_masked = attended * mask\n",
        "        seq_lengths = mask.sum(dim=1, keepdim=True)\n",
        "        pooled = attended_masked.sum(dim=1) / (seq_lengths + 1e-8)\n",
        "\n",
        "        # Final projection\n",
        "        text_embedding = self.projection(pooled)\n",
        "\n",
        "        return text_embedding\n"
      ],
      "metadata": {
        "id": "BQdo6w3Iy6_1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"Text-conditioned Generator for image synthesis\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=100, text_embedding_dim=128, img_channels=3, img_size=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.text_embedding_dim = text_embedding_dim\n",
        "        self.img_channels = img_channels\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Text conditioning layer\n",
        "        self.text_projection = nn.Sequential(\n",
        "            nn.Linear(text_embedding_dim, latent_dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Generator network\n",
        "        self.model = nn.Sequential(\n",
        "            # Input: latent_dim + latent_dim (for text)\n",
        "            nn.Linear(latent_dim * 2, 256 * 8 * 8),\n",
        "            nn.BatchNorm1d(256 * 8 * 8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 8, 8)),\n",
        "\n",
        "            # Upsampling layers\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 16x16\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 32x32\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1),  # 64x64\n",
        "            nn.Tanh()  # Output between -1 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, z, text_embedding):\n",
        "        # Project text embedding to match latent dimension\n",
        "        text_proj = self.text_projection(text_embedding)\n",
        "\n",
        "        # Concatenate latent vector and text projection\n",
        "        combined_input = torch.cat((z, text_proj), dim=1)\n",
        "\n",
        "        # Generate image\n",
        "        img = self.model(combined_input)\n",
        "\n",
        "        return img"
      ],
      "metadata": {
        "id": "oz_-kihJzF1B"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}