{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vXMBAZXEwHeb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "sB-fI-O0xitL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShapeDataset(Dataset):\n",
        "    \"\"\"Custom dataset for generating shapes with labels\"\"\"\n",
        "\n",
        "    def __init__(self, num_samples=10000, img_size=64, transform=None):\n",
        "        self.num_samples = num_samples\n",
        "        self.img_size = img_size\n",
        "        self.transform = transform\n",
        "        self.classes = ['circle', 'square', 'triangle']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def generate_circle(self, img_size):\n",
        "        \"\"\"Generate a circle image\"\"\"\n",
        "        img = Image.new('L', (img_size, img_size), 0)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        radius = np.random.randint(img_size//6, img_size//3)\n",
        "        center_x = np.random.randint(radius, img_size - radius)\n",
        "        center_y = np.random.randint(radius, img_size - radius)\n",
        "        draw.ellipse([center_x - radius, center_y - radius,\n",
        "                     center_x + radius, center_y + radius], fill=255)\n",
        "        return img\n",
        "\n",
        "    def generate_square(self, img_size):\n",
        "        \"\"\"Generate a square image\"\"\"\n",
        "        img = Image.new('L', (img_size, img_size), 0)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        size = np.random.randint(img_size//4, img_size//2)\n",
        "        x = np.random.randint(0, img_size - size)\n",
        "        y = np.random.randint(0, img_size - size)\n",
        "        draw.rectangle([x, y, x + size, y + size], fill=255)\n",
        "        return img\n",
        "\n",
        "    def generate_triangle(self, img_size):\n",
        "        \"\"\"Generate a triangle image\"\"\"\n",
        "        img = Image.new('L', (img_size, img_size), 0)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        size = np.random.randint(img_size//4, img_size//2)\n",
        "        x = np.random.randint(size//2, img_size - size//2)\n",
        "        y = np.random.randint(size//2, img_size - size//2)\n",
        "        points = [(x, y - size//2), (x - size//2, y + size//2), (x + size//2, y + size//2)]\n",
        "        draw.polygon(points, fill=255)\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Randomly select a class\n",
        "        class_idx = np.random.randint(0, len(self.classes))\n",
        "        class_name = self.classes[class_idx]\n",
        "\n",
        "        # Generate corresponding shape\n",
        "        if class_name == 'circle':\n",
        "            img = self.generate_circle(self.img_size)\n",
        "        elif class_name == 'square':\n",
        "            img = self.generate_square(self.img_size)\n",
        "        else:  # triangle\n",
        "            img = self.generate_triangle(self.img_size)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, class_idx"
      ],
      "metadata": {
        "id": "2CHu3zp-xm4F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"Conditional Generator for CGAN\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=100, num_classes=3, img_channels=1, img_size=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.img_channels = img_channels\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Label embedding\n",
        "        self.label_embedding = nn.Embedding(num_classes, latent_dim)\n",
        "\n",
        "        # Generator network\n",
        "        self.model = nn.Sequential(\n",
        "            # Input: latent_dim + latent_dim (for label)\n",
        "            nn.Linear(latent_dim * 2, 256 * 8 * 8),\n",
        "            nn.BatchNorm1d(256 * 8 * 8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 8, 8)),\n",
        "\n",
        "            # Upsampling layers\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),  # 16x16\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),   # 32x32\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, img_channels, 4, 2, 1),  # 64x64\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # Embed labels\n",
        "        label_embed = self.label_embedding(labels)\n",
        "\n",
        "        # Concatenate noise and label embedding\n",
        "        gen_input = torch.cat((noise, label_embed), dim=1)\n",
        "\n",
        "        # Generate image\n",
        "        img = self.model(gen_input)\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "ZYLjZ2bOxtJR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Conditional Discriminator for CGAN\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=3, img_channels=1, img_size=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.img_channels = img_channels\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Label embedding\n",
        "        self.label_embedding = nn.Embedding(num_classes, img_size * img_size)\n",
        "\n",
        "        # Discriminator network\n",
        "        self.model = nn.Sequential(\n",
        "            # Input: img_channels + 1 (for embedded label)\n",
        "            nn.Conv2d(img_channels + 1, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 8 * 8, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        # Embed labels and reshape to match image dimensions\n",
        "        label_embed = self.label_embedding(labels)\n",
        "        label_embed = label_embed.view(label_embed.size(0), 1, self.img_size, self.img_size)\n",
        "\n",
        "        # Concatenate image and label\n",
        "        disc_input = torch.cat((img, label_embed), dim=1)\n",
        "\n",
        "        # Get validity score\n",
        "        validity = self.model(disc_input)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "oZLpfz91xtGP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CGANTrainer:\n",
        "    \"\"\"Trainer class for Conditional GAN\"\"\"\n",
        "\n",
        "    def __init__(self, latent_dim=100, num_classes=3, img_channels=1, img_size=64,\n",
        "                 lr=0.0002, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.device = device\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # Initialize models\n",
        "        self.generator = Generator(latent_dim, num_classes, img_channels, img_size).to(device)\n",
        "        self.discriminator = Discriminator(num_classes, img_channels, img_size).to(device)\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = nn.BCELoss()\n",
        "\n",
        "        # Optimizers\n",
        "        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "        self.optimizer_D = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "        # Training metrics\n",
        "        self.train_history = {'g_loss': [], 'd_loss': [], 'accuracy': []}\n",
        "\n",
        "    def train(self, dataloader, num_epochs=100, save_interval=10):\n",
        "        \"\"\"Train the CGAN\"\"\"\n",
        "        print(f\"Training on device: {self.device}\")\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_g_loss = 0\n",
        "            epoch_d_loss = 0\n",
        "            correct_predictions = 0\n",
        "            total_predictions = 0\n",
        "\n",
        "            progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "            for i, (real_imgs, real_labels) in enumerate(progress_bar):\n",
        "                batch_size = real_imgs.size(0)\n",
        "                real_imgs = real_imgs.to(self.device)\n",
        "                real_labels = real_labels.to(self.device)\n",
        "\n",
        "                # Create labels for real and fake data\n",
        "                real_validity = torch.ones(batch_size, 1).to(self.device)\n",
        "                fake_validity = torch.zeros(batch_size, 1).to(self.device)\n",
        "\n",
        "                # ---------------------\n",
        "                # Train Discriminator\n",
        "                # ---------------------\n",
        "                self.optimizer_D.zero_grad()\n",
        "\n",
        "                # Real images\n",
        "                real_pred = self.discriminator(real_imgs, real_labels)\n",
        "                d_real_loss = self.criterion(real_pred, real_validity)\n",
        "\n",
        "                # Fake images\n",
        "                noise = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
        "                fake_labels = torch.randint(0, self.num_classes, (batch_size,)).to(self.device)\n",
        "                fake_imgs = self.generator(noise, fake_labels)\n",
        "                fake_pred = self.discriminator(fake_imgs.detach(), fake_labels)\n",
        "                d_fake_loss = self.criterion(fake_pred, fake_validity)\n",
        "\n",
        "                # Total discriminator loss\n",
        "                d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "                d_loss.backward()\n",
        "                self.optimizer_D.step()\n",
        "\n",
        "                # -----------------\n",
        "                # Train Generator\n",
        "                # -----------------\n",
        "                self.optimizer_G.zero_grad()\n",
        "\n",
        "                # Generate fake images and get discriminator's opinion\n",
        "                fake_pred = self.discriminator(fake_imgs, fake_labels)\n",
        "                g_loss = self.criterion(fake_pred, real_validity)\n",
        "\n",
        "                g_loss.backward()\n",
        "                self.optimizer_G.step()\n",
        "\n",
        "                # Calculate accuracy (discriminator's ability to classify real vs fake)\n",
        "                real_acc = (real_pred > 0.5).float().mean()\n",
        "                fake_acc = (fake_pred <= 0.5).float().mean()\n",
        "                batch_acc = (real_acc + fake_acc) / 2\n",
        "\n",
        "                epoch_g_loss += g_loss.item()\n",
        "                epoch_d_loss += d_loss.item()\n",
        "                correct_predictions += batch_acc.item() * batch_size\n",
        "                total_predictions += batch_size\n",
        "\n",
        "                progress_bar.set_postfix({\n",
        "                    'D_loss': f'{d_loss.item():.4f}',\n",
        "                    'G_loss': f'{g_loss.item():.4f}',\n",
        "                    'Acc': f'{batch_acc.item():.4f}'\n",
        "                })\n",
        "\n",
        "            # Calculate epoch metrics\n",
        "            avg_g_loss = epoch_g_loss / len(dataloader)\n",
        "            avg_d_loss = epoch_d_loss / len(dataloader)\n",
        "            accuracy = correct_predictions / total_predictions\n",
        "\n",
        "            self.train_history['g_loss'].append(avg_g_loss)\n",
        "            self.train_history['d_loss'].append(avg_d_loss)\n",
        "            self.train_history['accuracy'].append(accuracy)\n",
        "\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}] - G_loss: {avg_g_loss:.4f}, '\n",
        "                  f'D_loss: {avg_d_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
        "\n",
        "            # Save sample images\n",
        "            if (epoch + 1) % save_interval == 0:\n",
        "                self.save_sample_images(epoch + 1)\n",
        "\n",
        "        print(\"Training completed!\")\n",
        "\n",
        "    def save_sample_images(self, epoch, num_samples=9):\n",
        "        \"\"\"Save sample generated images\"\"\"\n",
        "        self.generator.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Generate samples for each class\n",
        "            fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "            fig.suptitle(f'Generated Samples - Epoch {epoch}')\n",
        "\n",
        "            for i, class_name in enumerate(['circle', 'square', 'triangle']):\n",
        "                for j in range(3):\n",
        "                    noise = torch.randn(1, self.latent_dim).to(self.device)\n",
        "                    label = torch.tensor([i]).to(self.device)\n",
        "\n",
        "                    fake_img = self.generator(noise, label)\n",
        "                    fake_img = fake_img.cpu().squeeze().numpy()\n",
        "\n",
        "                    axes[i, j].imshow(fake_img, cmap='gray')\n",
        "                    axes[i, j].set_title(f'{class_name.capitalize()}')\n",
        "                    axes[i, j].axis('off')\n",
        "\n",
        "            os.makedirs('generated_samples', exist_ok=True)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'generated_samples/epoch_{epoch}.png')\n",
        "            plt.close()\n",
        "\n",
        "        self.generator.train()\n",
        "\n",
        "    def evaluate_model(self, test_dataloader):\n",
        "        \"\"\"Evaluate the model and calculate metrics\"\"\"\n",
        "        self.discriminator.eval()\n",
        "\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for real_imgs, real_labels in test_dataloader:\n",
        "                real_imgs = real_imgs.to(self.device)\n",
        "                real_labels = real_labels.to(self.device)\n",
        "\n",
        "                # Get discriminator predictions\n",
        "                predictions = self.discriminator(real_imgs, real_labels)\n",
        "\n",
        "                # Convert to binary predictions (real vs fake)\n",
        "                binary_preds = (predictions > 0.5).cpu().numpy().astype(int)\n",
        "                real_labels_binary = np.ones(len(real_labels))  # All are real images\n",
        "\n",
        "                all_predictions.extend(binary_preds.flatten())\n",
        "                all_labels.extend(real_labels_binary)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        precision = precision_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
        "        recall = recall_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "        print(f\"\\nModel Evaluation Results:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.savefig('confusion_matrix.png')\n",
        "        plt.show()\n",
        "\n",
        "        return accuracy, precision, recall\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"Plot training history\"\"\"\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.plot(self.train_history['g_loss'], label='Generator Loss')\n",
        "        plt.plot(self.train_history['d_loss'], label='Discriminator Loss')\n",
        "        plt.title('Training Losses')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.plot(self.train_history['accuracy'])\n",
        "        plt.title('Discriminator Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        # Show final accuracy\n",
        "        final_acc = self.train_history['accuracy'][-1] if self.train_history['accuracy'] else 0\n",
        "        plt.bar(['Final Accuracy'], [final_acc])\n",
        "        plt.title('Final Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.ylim(0, 1)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_history.png')\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, path='models'):\n",
        "        \"\"\"Save the trained models\"\"\"\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "        torch.save({\n",
        "            'generator_state_dict': self.generator.state_dict(),\n",
        "            'discriminator_state_dict': self.discriminator.state_dict(),\n",
        "            'optimizer_G_state_dict': self.optimizer_G.state_dict(),\n",
        "            'optimizer_D_state_dict': self.optimizer_D.state_dict(),\n",
        "            'train_history': self.train_history\n",
        "        }, os.path.join(path, 'cgan_checkpoint.pth'))\n",
        "\n",
        "        # Save just the generator for inference\n",
        "        torch.save(self.generator.state_dict(), os.path.join(path, 'generator.pth'))\n",
        "\n",
        "        print(f\"Models saved to {path}/\")\n",
        "\n",
        "    def generate_samples_by_class(self, class_name, num_samples=5):\n",
        "        \"\"\"Generate samples for a specific class\"\"\"\n",
        "        self.generator.eval()\n",
        "\n",
        "        class_to_idx = {'circle': 0, 'square': 1, 'triangle': 2}\n",
        "        if class_name not in class_to_idx:\n",
        "            print(f\"Invalid class name. Choose from: {list(class_to_idx.keys())}\")\n",
        "            return\n",
        "\n",
        "        class_idx = class_to_idx[class_name]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 2, 2))\n",
        "            if num_samples == 1:\n",
        "                axes = [axes]\n",
        "\n",
        "            for i in range(num_samples):\n",
        "                noise = torch.randn(1, self.latent_dim).to(self.device)\n",
        "                label = torch.tensor([class_idx]).to(self.device)\n",
        "\n",
        "                fake_img = self.generator(noise, label)\n",
        "                fake_img = fake_img.cpu().squeeze().numpy()\n",
        "\n",
        "                axes[i].imshow(fake_img, cmap='gray')\n",
        "                axes[i].set_title(f'{class_name.capitalize()} {i+1}')\n",
        "                axes[i].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'generated_{class_name}_samples.png')\n",
        "            plt.show()\n",
        "\n",
        "        self.generator.train()"
      ],
      "metadata": {
        "id": "F-jw698uxtDZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main training function\"\"\"\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Data transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = ShapeDataset(num_samples=8000, transform=transform)\n",
        "    test_dataset = ShapeDataset(num_samples=2000, transform=transform)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "    print(f\"Training samples: {len(train_dataset)}\")\n",
        "    print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = CGANTrainer(device=device)\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Starting CGAN training...\")\n",
        "    trainer.train(train_loader, num_epochs=20, save_interval=20)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(\"\\nEvaluating model...\")\n",
        "    accuracy, precision, recall = trainer.evaluate_model(test_loader)\n",
        "\n",
        "    # Plot training history\n",
        "    trainer.plot_training_history()\n",
        "\n",
        "    # Generate samples for each class\n",
        "    print(\"\\nGenerating sample images...\")\n",
        "    for class_name in ['circle', 'square', 'triangle']:\n",
        "        trainer.generate_samples_by_class(class_name, num_samples=5)\n",
        "\n",
        "    # Save the trained model\n",
        "    trainer.save_model()\n",
        "\n",
        "    # Save training metrics\n",
        "    metrics = {\n",
        "        'final_accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'training_history': trainer.train_history\n",
        "    }\n",
        "\n",
        "    with open('training_metrics.json', 'w') as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "\n",
        "    print(f\"\\nTraining completed successfully!\")\n",
        "    print(f\"Final Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    if accuracy >= 0.7:\n",
        "        print(\"Model meets the 70% accuracy requirement!\")\n",
        "    else:\n",
        "        print(\"Model accuracy is below 70%. Consider training longer or adjusting hyperparameters.\")\n"
      ],
      "metadata": {
        "id": "7XtkhTq-yAzu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBFlkFonyAwS",
        "outputId": "fa527f69-6c08-4684-f366-7345c18f724e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Training samples: 8000\n",
            "Test samples: 2000\n",
            "Starting CGAN training...\n",
            "Training on device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|██████████| 125/125 [06:08<00:00,  2.94s/it, D_loss=0.2498, G_loss=2.5015, Acc=0.9297]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20] - G_loss: 2.4975, D_loss: 0.3246, Accuracy: 0.9159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|██████████| 125/125 [06:02<00:00,  2.90s/it, D_loss=0.1707, G_loss=3.6550, Acc=0.9766]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/20] - G_loss: 2.6607, D_loss: 0.3326, Accuracy: 0.9053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|██████████| 125/125 [06:02<00:00,  2.90s/it, D_loss=0.4709, G_loss=2.2745, Acc=0.6484]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/20] - G_loss: 2.8539, D_loss: 0.2742, Accuracy: 0.9242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/20:  42%|████▏     | 53/125 [02:33<03:26,  2.87s/it, D_loss=0.3669, G_loss=4.3628, Acc=1.0000]"
          ]
        }
      ]
    }
  ]
}